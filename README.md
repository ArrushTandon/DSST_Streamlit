
# ğŸ§  DSST - Domain-Specific Speech Transcription Using Whisper

This project implements **Domain-Specific Speech Transcription (DSST)** using OpenAI's Whisper model. It transcribes audio commands, extracts **robot movement instructions**, calculates **Character Error Rate (CER)**, and presents everything through a **Streamlit-powered web app**.

---

## ğŸŒ Live App

ğŸ‘‰ [Launch DSST Web App](https://dsst-streamlit-yourusername.streamlit.app)

---

## ğŸ“¦ Features

- ğŸ™ **Whisper-based transcription** for `.wav`, `.mp3`, `.flac`, etc.
- ğŸ¤– **NLP-based command extraction** for robotics use cases
- ğŸ“‰ **CER evaluation** using Levenshtein distance
- ğŸ§ª Optional ground truth comparison for accuracy checking
- ğŸ§µ Modular Python architecture with reusable components
- ğŸ’» Web UI built with **Streamlit** and deployed on **Streamlit Cloud**
- ğŸ¨ Tab-based UI with landing page, upload interface, and settings

---

## ğŸ—‚ï¸ Folder Structure

```
dsst_streamlit/
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml         # Theme config (dark mode)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”œâ”€â”€ cer_calculator.py
â”‚   â”œâ”€â”€ nlp_processor.py
â”‚   â””â”€â”€ file_utils.py
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ robot_runner.py
â”‚   â”œâ”€â”€ batch_nptel_runner.py
â”‚   â””â”€â”€ folder_eval_runner.py
```

---

## ğŸš€ Try It Locally

### 1. Clone the repository
```bash
git clone https://github.com/ArrushTandon/DSST_Streamlit.git
cd DSST_Streamlit
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate     # On Windows: venv\Scripts\activate
```

### 3. Install requirements
```bash
pip install -r requirements.txt
```

### 4. Run the app
```bash
streamlit run app.py
```

---

## ğŸ“‹ How It Works

### ğŸ¤ Audio Input
Upload an audio file containing natural spoken commands (e.g., "move forward by 3 meters").

### ğŸ” Transcription
Whisper transcribes audio using the `"base"` model.

### ğŸ§  Command Extraction
Natural Language Processing extracts structured robot commands using rules.

### ğŸ“‰ CER Calculation (Optional)
If ground truth is provided, CER is calculated for evaluation.

---

## ğŸ’» Streamlit UI

| Tab | Description |
|-----|-------------|
| ğŸ  **Welcome** | Intro, project info, usage |
| ğŸ“¤ **Upload & Transcribe** | Upload audio + ground truth, see results |
| âš™ï¸ **Settings** | About, model details |

---

## âš™ï¸ Tech Stack

- [x] ğŸ§  Whisper (OpenAI)
- [x] ğŸ”Š Librosa for audio loading
- [x] âœ‚ Levenshtein for CER
- [x] âš™ Python 3.11
- [x] ğŸŒ Streamlit for the web app

---

## ğŸ“ˆ Evaluation Metric

**Character Error Rate (CER)**:
```text
CER = (Insertions + Deletions + Substitutions) / Total Characters
```

Lower CER = Better transcription accuracy âœ…

---

## ğŸ“„ License

MIT License (or your preferred license here)

---

## ğŸ¤ Contributing

Got ideas? Found a bug?  
Feel free to fork this repo, submit an issue, or create a pull request.

---

## ğŸ™‹â€â™‚ï¸ Author

**Arrush Tandon**  
ğŸ“§ arrush6674@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/arrush-tandon/)

---

> â€œTurning voice into understanding â€” one command at a time.â€ ğŸ™ï¸ğŸ¤–
